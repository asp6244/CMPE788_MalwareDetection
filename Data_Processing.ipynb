{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'C:\\\\Users\\\\alecs\\\\OneDrive\\\\Docs\\\\RIT\\\\MLforCybersec\\\\SemesterProject\\\\ember-master')\n",
    "import ember\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "_ = alt.renderers.enable('notebook')\n",
    "\n",
    "data_dir_2017 = \"D:\\\\ML_Data\\\\EmberDataset\\\\ember2017\"\n",
    "data_dir_2018 = \"D:\\\\ML_Data\\\\EmberDataset\\\\ember2018\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter data to include only labeled samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter data from datasets to only include labeled samples\n",
    "import os\n",
    "import json\n",
    "\n",
    "filter_data = False\n",
    "if filter_data:\n",
    "    data_dirs = [data_dir_2017, data_dir_2018]\n",
    "\n",
    "    # Iterate over both datasets\n",
    "    for data_dir in data_dirs:\n",
    "        raw_feature_paths = [\"train_features_{}.jsonl\".format(i) for i in range(6)]\n",
    "        raw_feature_paths.append(\"test_features.jsonl\")\n",
    "\n",
    "        # Iterate over all jsonl files\n",
    "        for filename in raw_feature_paths:\n",
    "            # Open the origin file in read mode\n",
    "            with open(os.path.join(data_dir, \"origin\", filename), 'r') as file:\n",
    "                # Open the processed file in write mode\n",
    "                with open(os.path.join(data_dir, filename), 'w') as newFile:\n",
    "                    # Iterate over each line in the old file\n",
    "                    for line in file:\n",
    "                        # Write each line that is labeled into the new file\n",
    "                        diction = json.loads(line)\n",
    "                        if diction[\"label\"] != -1:\n",
    "                            newFile.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorize Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "vectorize_2017_features = False\n",
    "if vectorize_2017_features:\n",
    "    # Vectorize 2017 dataset 2\n",
    "    ember.create_vectorized_features(data_dir_2017, feature_version=2)\n",
    "    ember.create_metadata(data_dir_2017)\n",
    "\n",
    "vectorize_2018_features = False\n",
    "if vectorize_2018_features:\n",
    "    # Vectorize 2017 dataset 1\n",
    "    ember.create_vectorized_features(data_dir_2018, feature_version=2)\n",
    "    ember.create_metadata(data_dir_2018)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot distribution of 2017 dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying chart at http://localhost:60704/\n"
     ]
    }
   ],
   "source": [
    "build_charts = True\n",
    "\n",
    "if build_charts:\n",
    "    emberdf_2017 = ember.read_metadata(data_dir_2017)\n",
    "\n",
    "    map_dict = {\n",
    "        0: \"benign\",\n",
    "        1: \"malicious\"\n",
    "    }\n",
    "\n",
    "    plotdf = emberdf_2017.copy()\n",
    "    plotdf[\"label\"] = plotdf[\"label\"].map(map_dict)\n",
    "    gbdf = plotdf.groupby([\"label\", \"subset\"]).count().reset_index()\n",
    "    subsetChart = alt.Chart(gbdf).mark_bar().encode(\n",
    "        alt.X('subset:O', axis=alt.Axis(title='Subset')),\n",
    "        alt.Y('sum(sha256):Q', axis=alt.Axis(title='Number of samples')),\n",
    "        alt.Color('label:N', scale=alt.Scale(range=[\"#3333ff\", \"#ff3333\"]))\n",
    "    )\n",
    "\n",
    "    plotdf = emberdf_2017.copy()\n",
    "    plotdf[\"label\"] = plotdf[\"label\"].map(map_dict)\n",
    "    plotdf.loc[plotdf[\"appeared\"] < \"2017-01\", \"appeared\"] = \" <2017\"\n",
    "    gbdf = plotdf.groupby([\"appeared\", \"label\"]).count().reset_index()\n",
    "    appearedChart = alt.Chart(gbdf).mark_bar().encode(\n",
    "        alt.X('appeared:O', axis=alt.Axis(title='Month appeared')),\n",
    "        alt.Y('sum(sha256):Q', axis=alt.Axis(title='Number of samples')),\n",
    "        alt.Color('label:N', scale=alt.Scale(range=[\"#3333ff\", \"#ff3333\"]))\n",
    "    )\n",
    "\n",
    "    chart = alt.hconcat(subsetChart, appearedChart).properties(\n",
    "        title='Distribution of 2017 Dataset Across Subset and Month Appeared'\n",
    "    )\n",
    "\n",
    "    chart.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot Distribution of 2018 dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying chart at http://localhost:60704/\n"
     ]
    }
   ],
   "source": [
    "if build_charts:\n",
    "    emberdf_2018 = ember.read_metadata(data_dir_2018)\n",
    "\n",
    "    plotdf = emberdf_2018.copy()\n",
    "    plotdf[\"label\"] = plotdf[\"label\"].map(map_dict)\n",
    "    gbdf = plotdf.groupby([\"label\", \"subset\"]).count().reset_index()\n",
    "    subsetChart = alt.Chart(gbdf).mark_bar().encode(\n",
    "        alt.X('subset:O', axis=alt.Axis(title='Subset')),\n",
    "        alt.Y('sum(sha256):Q', axis=alt.Axis(title='Number of samples')),\n",
    "        alt.Color('label:N', scale=alt.Scale(range=[\"#3333ff\", \"#ff3333\"]))\n",
    "    )\n",
    "\n",
    "    plotdf = emberdf_2018.copy()\n",
    "    plotdf[\"label\"] = plotdf[\"label\"].map(map_dict)\n",
    "    plotdf.loc[plotdf[\"appeared\"] < \"2018-01\", \"appeared\"] = \" <2018\"\n",
    "    gbdf = plotdf.groupby([\"appeared\", \"label\"]).count().reset_index()\n",
    "    appearedChart = alt.Chart(gbdf).mark_bar().encode(\n",
    "        alt.X('appeared:O', axis=alt.Axis(title='Month appeared')),\n",
    "        alt.Y('sum(sha256):Q', axis=alt.Axis(title='Number of samples')),\n",
    "        alt.Color('label:N', scale=alt.Scale(range=[\"#3333ff\", \"#ff3333\"]))\n",
    "    )\n",
    "\n",
    "    chart = alt.hconcat(subsetChart, appearedChart).properties(\n",
    "        title='Distribution of 2018 Dataset Across Subset and Month Appeared'\n",
    "    )\n",
    "\n",
    "    chart.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train simple gradient boosting decision tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "use_lgbm = False\n",
    "if use_lgbm:\n",
    "    X_train_2017, y_train_2017, X_test_2017, y_test_2017 = ember.read_vectorized_features(data_dir_2017, feature_version=2)\n",
    "    X_train_2018, y_train_2018, X_test_2018, y_test_2018 = ember.read_vectorized_features(data_dir_2018, feature_version=2)\n",
    "\n",
    "    train_model = False\n",
    "    if train_model:\n",
    "        params = {'metric': 'binary',\n",
    "                  'learning_rate': 0.05,\n",
    "                  'num_leaves': 2048,\n",
    "                  'max_depth': 15,\n",
    "                  'min_data_in_leaf': 50,\n",
    "                  'feature_fraction': 0.5,\n",
    "                  'num_trees': 1000}\n",
    "        lgbm_model_2017 = ember.train_model(data_dir_2017, params)\n",
    "        lgbm_model_2018 = ember.train_model(data_dir_2018, params)\n",
    "    else:\n",
    "        lgbm_model_2017 = lgb.Booster(model_file=\"lgbm_model_2017.txt\")\n",
    "        lgbm_model_2018 = lgb.Booster(model_file=\"lgbm_model_2018.txt\")\n",
    "\n",
    "    lgbm_model_ember = lgb.Booster(model_file=os.path.join(data_dir_2018, \"ember_model_2018.txt\"))\n",
    "\n",
    "    y_train_pred_2017 = lgbm_model_2017.predict(X_train_2017)\n",
    "    y_test_pred_2017 = lgbm_model_2017.predict(X_test_2017)\n",
    "    y_train_pred_2018 = lgbm_model_2018.predict(X_train_2018)\n",
    "    y_test_pred_2018 = lgbm_model_2018.predict(X_test_2018)\n",
    "    y_test_pred_2017on2018 = lgbm_model_2017.predict(X_test_2018)\n",
    "    y_test_pred_2018_ember = lgbm_model_ember.predict(X_test_2018)\n",
    "\n",
    "    train_acc_2017 = np.sum(np.round(y_train_pred_2017) == y_train_2017) / len(y_train_2017) * 100.0\n",
    "    print(\"2017 model on 2017 training set: {:.1f}%\".format(train_acc_2017))\n",
    "    test_acc_2017 = np.sum(np.round(y_test_pred_2017) == y_test_2017) / len(y_test_2017) * 100.0\n",
    "    print(\"2017 model on 2017 testing set: {:.1f}%\".format(test_acc_2017))\n",
    "    train_acc_2018 = np.sum(np.round(y_train_pred_2018) == y_train_2018) / len(y_train_2018) * 100.0\n",
    "    print(\"2018 model on 2018 training set: {:.1f}%\".format(train_acc_2018))\n",
    "    test_acc_2018 = np.sum(np.round(y_test_pred_2018) == y_test_2018) / len(y_test_2018) * 100.0\n",
    "    print(\"2018 model on 2018 testing set: {:.1f}%\".format(test_acc_2018))\n",
    "    test_acc_2017on2018 = np.sum(np.round(y_test_pred_2017on2018) == y_test_2018) / len(y_test_2018) * 100.0\n",
    "    print(\"2017 model on 2018 testing set: {:.1f}%\".format(test_acc_2017on2018))\n",
    "    test_acc_2018_ember = np.sum(np.round(y_test_pred_2018_ember) == y_test_2018) / len(y_test_2018) * 100.0\n",
    "    print(\"Ember model on 2018 testing set: {:.1f}%\".format(test_acc_2018_ember))\n",
    "\n",
    "    lgbm_model_2017.save_model(\"lgbm_model_2017.txt\")\n",
    "    lgbm_model_2018.save_model(\"lgbm_model_2018.txt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
