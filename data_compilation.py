import sys
sys.path.insert(0, 'C:\\Users\\alecs\\OneDrive\\Docs\\RIT\\MLforCybersec\\SemesterProject\\ember-master')
import ember

import numpy as np
from sklearn.preprocessing import StandardScaler
import torch

data_dir_2017 = "D:\\ML_Data\\EmberDataset\\ember2017"
data_dir_2018 = "D:\\ML_Data\\EmberDataset\\ember2018"

all_months = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

def load_2017_data():
    # Load 2017 data from disk into RAM
    print("Copying 2017 data into RAM.")
    X_train_disk, y_train_disk, X_test_disk, y_test_disk = ember.read_vectorized_features(data_dir_2017, feature_version=2)
    X_2017 = np.concatenate((np.array(X_train_disk), np.array(X_test_disk)), axis=0)
    del X_train_disk, X_test_disk
    print("Copied 2017 parameter data.")
    y_2017 = np.concatenate((np.array(y_train_disk), np.array(y_test_disk)), axis=0)
    del y_train_disk, y_test_disk
    print("Copied 2017 ground-truth data.")
    print("Done.")
    return X_2017, y_2017


def load_2018_data():
    # Load 2018 data from disk into RAM
    print("Copying 2018 data into RAM.")
    X_train_disk, y_train_disk, X_test_disk, y_test_disk = ember.read_vectorized_features(data_dir_2018, feature_version=2)
    X_2018 = np.concatenate((np.array(X_train_disk), np.array(X_test_disk)), axis=0)
    del X_train_disk, X_test_disk
    print("Copied 2018 parameter data.")
    y_2018 = np.concatenate((np.array(y_train_disk), np.array(y_test_disk)), axis=0)
    del y_train_disk, y_test_disk
    print("Copied 2018 ground-truth data.")
    print("Done.")
    return X_2018, y_2018


def split_train_test_data(X, y, split):
    data_len = X.shape[0]
    random_indices = np.random.permutation(data_len)
    train_size = int(split*data_len)
    train_indices = random_indices[:train_size]
    test_indices = random_indices[train_size:]
    X_train = X[train_indices].copy()
    y_train = y[train_indices].copy()
    X_test = X[test_indices].copy()
    y_test = y[test_indices].copy()

    return X_train, y_train, X_test, y_test


def split_2018_data_monthly(X, y, split):
    emberdf_2018 = ember.read_metadata(data_dir_2018)
    all_months_str = ['2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06',
                      '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12']

    # Create a separate DataLoader for each month
    all_data = {}
    for month in all_months:
        # Get indices of samples for specific month
        indices = emberdf_2018[emberdf_2018['appeared'] == all_months_str[month]].index
        # Split data between training and testing set
        X_train, y_train, X_test, y_test = split_train_test_data(X[indices], y[indices], split)
        # Create data array
        all_data[month] = (X_train, y_train, X_test, y_test)

    return all_data


def create_scaler(X):
    # Create an instance of the StandardScaler class
    scaler = StandardScaler()

    # Fit the scaler to the 2017 training data
    print("Building scaler")
    scaler.fit(X)

    return scaler


def standardize_2017_features(X_train, X_test, scaler, build_model=True, verbose=False):
    if verbose:
        print("Mean of 2017 training data:", X_train.mean(axis=0))
        print("Standard deviation of 2017 training data:", X_train.std(axis=0))
        print("Mean of 2017 testing data:", X_test.mean(axis=0))
        print("Standard deviation of 2017 testing data:", X_test.std(axis=0))

    # Transform both the 2017 training and testing data using the scaler
    if build_model:
        print("Scaling 2017 training data")
        X_train = scaler.transform(X_train)
    print("Scaling 2017 testing data")
    X_test = scaler.transform(X_test)

    if verbose:
        print("Mean of standardized 2017 training data:", X_train.mean(axis=0))
        print("Standard deviation of standardized 2017 training data:", X_train.std(axis=0))
        print("Mean of standardized 2017 testing data:", X_test.mean(axis=0))
        print("Standard deviation of standardized 2017 testing data:", X_test.std(axis=0))

    return X_train, X_test


def standardize_2018_features(all_data, scaler, build_model=True, verbose=False):
    if verbose:
        print("Mean of 2018 training data:", np.mean([month[0].mean(axis=0) for month in all_data]))
        print("Standard deviation of 2018 training data:", np.std([month[0].mean(axis=0) for month in all_data]))
        print("Mean of 2018 testing data:", np.mean([month[1].mean(axis=0) for month in all_data]))
        print("Standard deviation of 2018 testing data:", np.std([month[1].mean(axis=0) for month in all_data]))

    # Standardize 2018 feature space with the given scaler
    if build_model:
        print("Scaling 2018 training and testing data")
    else:
        print("Scaling 2018 testing data")

    for month in all_months:
        (X_train, y_train, X_test, y_test) = all_data[month]
        if build_model:
            X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        all_data[month] = (X_train, y_train, X_test, y_test)

    if verbose:
        print("Mean of standardized 2018 training data:", np.mean([month[0].mean(axis=0) for month in all_data]))
        print("Standard deviation of standardized 2018 training data:", np.std([month[0].mean(axis=0) for month in all_data]))
        print("Mean of standardized 2018 testing data:", np.mean([month[1].mean(axis=0) for month in all_data]))
        print("Standard deviation of standardized 2018 testing data:", np.std([month[1].mean(axis=0) for month in all_data]))

    return all_data


def move_data_to_device(X, y, device):
    X = torch.from_numpy(X).to(device)
    y = torch.from_numpy(y)
    y = torch.reshape(y, (y.shape[0], 1)).to(device)

    return X, y


def move_2018_test_to_device(all_data, device):
    for month in all_months:
        (X_train, y_train, X_test, y_test) = all_data[month]
        X_test, y_test = move_data_to_device(X_test, y_test, device)
        all_data[month] = (X_train, y_train, X_test, y_test)

    return all_data


def move_2018_train_to_device(all_data, device):
    for month in all_months:
        (X_train, y_train, X_test, y_test) = all_data[month]
        X_train, y_train = move_data_to_device(X_train, y_train, device)
        all_data[month] = (X_train, y_train, X_test, y_test)

    return all_data