# CMPE788_MalwareDetection
This repository hosts a continuous learning approach to static malware detection for CMPE-788 at the Rochester Institute of Technology in the
spring of 2023. In summary, a model is trained until convergence on data from 2017 and before. Then, continuous learning
that would occur in a real scenario is simulated using new data from 2018.

This work is built off of that done by 
Rahman et al. https://proceedings.mlr.press/v199/rahman22a.html.

## Dependencies
This project requires the EMBER dataset, which can be found at:

https://arxiv.org/abs/1804.04637

https://github.com/elastic/ember

Note: this repository was developed while using an NVIDIA GeForce 1080 Ti, with 11 GB of vram. In its current state, at
least 10 GB is probably necessary. The repository currently moves all necessary data to the GPU and keeps it there
during the duration of the training. However, the code can be refactored to move data to GPU as they are needed,
reducing the vram requirement.

## Project Structure

Data_Processing.ipynb --
This jupyter notebook will take the original EMBER dataset and process the data to make it compatible with this 
repository. It also plots distributions of data and trains a simple gradient boosting decision tree with the data.

data_compilation.py --
This file contains several functions that are used to load data from disk into RAM, split the data between training and
testing, standardize the datasets, and move the data to the GPU.

malware_classifier.py --
This file contains the neural network model that is trained, some classes and functions to assist in building a
dataloader, and a class to assist in training and testing of the model.

data_visualizer.py --
This file contains functions to assist in plotting the training and testing data.

free_memory.py --
This file includes functions that are used to clear memory from GPUs. Found at
https://stackoverflow.com/questions/70508960/how-to-free-gpu-memory-in-pytorch.

### EMBER Dataset Setup:
Each experiment notebook will process the data in the following way using some of the functions mentioned above.

2017 --
Combine all months into one set. Split data 80:20 between training and testing based on normal distribution across all
months. This ensures that the last 2 months of data (which were initially exclusively for testing) are adequately 
learned. 50:50 split between malicious and benign for both training and testing sets.

2018 --
Discard data from <2018 to focus on new data that has not yet been trained on. For each month, split data 80:20 between
training and testing based on normal

### Experiments

Experiment1.ipynb --
This jupyter notebook will build two models: one model is only trained on 2017 data, one model is only trained on 2018
data, both models are tested using separate 2017 and 2018 testing sets. The results are plotted.

Experiment2.ipynb --
This jupyter notebook will perform continuous learning. A model is trained on 2017 training data until convergence.
Then, the model is retrained on the testing set of each month, month by month, sequentially, to simulate data that has
been collected in a real scenario. For each month, test on 2017 and 2018 testing sets to determine performance over.
The results are plotted.

Experiment3.ipynb --
This jupyter notebook will perform continuous learning with replay. Replay is when a certain amount of data that has 
been previously trained on it saved to continue to train on it later; this should reduce catastrophic forgetting. Replay
amounts of 0% (same as Experiment 2), 1%, 5%, 10%, 20%, and 50% are tested. First, the 2017 model from Experiment 1 is
loaded. Then for each replay amount, experiment 2 is repeated. After training on each month, the replay amount of each
training set is saved to a replay array, and the replay array is combined with the training data of the next month
being trained on. When training on the next month, the model is actually trained on both the new data and some old data.
The results are plotted.

MalwareDetection.ipynb --
This jupyter notebook will try to classify binaries as malware or benign using a model built in a previous experiment.
Note that the code is currently not working and hangs when processing the binary. While it is possible to classify
benign binaries, many malicious binaries are not distributed to the public and are not accessible to test without 
special permission.

## Final Presentation
Final presentation on project and the results can be found at
https://drive.google.com/file/d/1HSnOAus2TluCnBP1WDEaL6fNUkbj_7yF/view?usp=sharing

